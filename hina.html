<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Edge Detection with Camera Switch</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            overflow: hidden; /* スクロールを無効化 */
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #000;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover; /* 画面全体を埋める */
        }
        #switchButton {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(255, 255, 255, 0.8);
            border: none;
            padding: 10px;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            z-index: 10; /* ボタンが映像より前面に表示されるように */
        }
    </style>
</head>
<body>
    <button id="switchButton">Switch Camera</button>
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const switchButton = document.getElementById('switchButton');
        const ctx = canvas.getContext('2d');

        let currentStream = null;
        let usingEnvironmentCamera = true;
        let showEdgeDetection = true;

        async function startCamera(facingMode = 'environment') {
            // 現在のカメラストリームを停止
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }

            // 新しいカメラストリームを開始
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode },
                });
                currentStream = stream;
                video.srcObject = stream;
            } catch (err) {
                console.error('カメラアクセスエラー:', err);
            }
        }

        function edgeDetection() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;

            const width = canvas.width;
            const height = canvas.height;
            const edgeData = new Uint8ClampedArray(data.length);

            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    const i = (y * width + x) * 4;

                    const gx = (
                        -1 * data[(y - 1) * width * 4 + (x - 1) * 4] +
                        1 * data[(y - 1) * width * 4 + (x + 1) * 4] +
                        -2 * data[y * width * 4 + (x - 1) * 4] +
                        2 * data[y * width * 4 + (x + 1) * 4] +
                        -1 * data[(y + 1) * width * 4 + (x - 1) * 4] +
                        1 * data[(y + 1) * width * 4 + (x + 1) * 4]
                    );

                    const gy = (
                        -1 * data[(y - 1) * width * 4 + (x - 1) * 4] +
                        -2 * data[(y - 1) * width * 4 + x * 4] +
                        -1 * data[(y - 1) * width * 4 + (x + 1) * 4] +
                        1 * data[(y + 1) * width * 4 + (x - 1) * 4] +
                        2 * data[(y + 1) * width * 4 + x * 4] +
                        1 * data[(y + 1) * width * 4 + (x + 1) * 4]
                    );

                    const magnitude = Math.sqrt(gx * gx + gy * gy);
                    edgeData[i] = edgeData[i + 1] = edgeData[i + 2] = magnitude > 128 ? 255 : 0;
                    edgeData[i + 3] = 255; // Full alpha
                }
            }

            ctx.putImageData(new ImageData(edgeData, width, height), 0, 0);
        }

        video.addEventListener('play', () => {
            function processFrame() {
                if (!video.paused && !video.ended) {
                    if (showEdgeDetection) {
                        edgeDetection();
                    } else {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                    }
                    requestAnimationFrame(processFrame);
                }
            }
            processFrame();
        });

        // カメラ切り替え
        switchButton.addEventListener('click', () => {
            usingEnvironmentCamera = !usingEnvironmentCamera;
            const facingMode = usingEnvironmentCamera ? 'environment' : 'user';
            startCamera(facingMode);
        });

        // タップで表示を切り替える
        canvas.addEventListener('touchstart', () => {
            showEdgeDetection = !showEdgeDetection;
        });

        // 初期カメラを開始
        startCamera();
    </script>
</body>
</html>
