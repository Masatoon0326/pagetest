<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Edge Detection on Uploaded Video</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            overflow: hidden; /* スクロールを無効化 */
            background-color: #000;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover; /* 画面全体を埋める */
            display: none; /* 初期状態では非表示 */
        }
        canvas {
            display: block; /* 初期状態でエッジ検出結果を表示 */
        }
        #uploadButton {
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(255, 255, 255, 0.8);
            border: none;
            padding: 10px;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            z-index: 10; /* ボタンが映像より前面に表示されるように */
        }
    </style>
</head>
<body>
    <button id="uploadButton">Upload Video</button>
    <input type="file" id="videoInput" accept="video/*" style="display:none;">
    <video id="video" autoplay playsinline loop muted></video>
    <canvas id="canvas"></canvas>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const uploadButton = document.getElementById('uploadButton');
        const videoInput = document.getElementById('videoInput');
        const ctx = canvas.getContext('2d');

        let showEdgeDetection = true;

        // 動画のアップロードボタンのクリックイベント
        uploadButton.addEventListener('click', () => {
            videoInput.click();
        });

        // 動画ファイル選択時の処理
        videoInput.addEventListener('change', () => {
            const file = videoInput.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                video.src = url;
                video.play();
                canvas.style.display = 'block'; // エッジ検出結果を最初に表示
                video.style.display = 'none';  // 動画は非表示
            }
        });

        function edgeDetection() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;

            const width = canvas.width;
            const height = canvas.height;
            const edgeData = new Uint8ClampedArray(data.length);

            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    const i = (y * width + x) * 4;

                    const gx = (
                        -1 * data[(y - 1) * width * 4 + (x - 1) * 4] +
                        1 * data[(y - 1) * width * 4 + (x + 1) * 4] +
                        -2 * data[y * width * 4 + (x - 1) * 4] +
                        2 * data[y * width * 4 + (x + 1) * 4] +
                        -1 * data[(y + 1) * width * 4 + (x - 1) * 4] +
                        1 * data[(y + 1) * width * 4 + (x + 1) * 4]
                    );

                    const gy = (
                        -1 * data[(y - 1) * width * 4 + (x - 1) * 4] +
                        -2 * data[(y - 1) * width * 4 + x * 4] +
                        -1 * data[(y - 1) * width * 4 + (x + 1) * 4] +
                        1 * data[(y + 1) * width * 4 + (x - 1) * 4] +
                        2 * data[(y + 1) * width * 4 + x * 4] +
                        1 * data[(y + 1) * width * 4 + (x + 1) * 4]
                    );

                    const magnitude = Math.sqrt(gx * gx + gy * gy);
                    const isEdge = magnitude > 128;

                    edgeData[i] = edgeData[i + 1] = edgeData[i + 2] = isEdge ? 255 : 0;
                    edgeData[i + 3] = 255; // Full alpha
                }
            }

            ctx.putImageData(new ImageData(edgeData, width, height), 0, 0);
        }

        video.addEventListener('play', () => {
            function processFrame() {
                if (!video.paused && !video.ended) {
                    if (showEdgeDetection) {
                        edgeDetection();
                    }
                    requestAnimationFrame(processFrame);
                }
            }
            processFrame();
        });

        // タップで表示を切り替える
        document.body.addEventListener('touchstart', () => {
            showEdgeDetection = !showEdgeDetection;
            if (showEdgeDetection) {
                canvas.style.display = 'block';
                video.style.display = 'none';
            } else {
                canvas.style.display = 'none';
                video.style.display = 'block';
            }
        });
    </script>
</body>
</html>
